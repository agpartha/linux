
----------------------------------ooOOOOoo---------------------------------------

libpcap:

Solution:
Install libpcap-dev package. libpcap install fails,

sudo apt-get install libpcap-dev
....
user@ubuntu:/$ whereis pcap
pcap: /usr/include/pcap.h /usr/include/pcap /usr/share/man/man3/pcap.3pcap.gz


Issue:
user@ubuntu:~/gDocuments/code/C-Snippets/Sandbox$ gcc -o ldev ldev.c -lpcap
ldev.c:12:46: fatal error: pcap.h: No such file or directory

user@ubuntu:~/gDocuments/code/C-Snippets/Sandbox$ whereis pcap.h
pcap:

user@ubuntu:/$ sudo apt-get libpcap
[sudo] password for user: 
E: Invalid operation libpcap


----------------------------------ooOOOOoo---------------------------------------

pcap_open_live:

unable to cpature as non root user.

Solution:

Do the following as root

Add a capture group and add yourself to it

groupadd pcap
usermod -a -G pcap $USER
Next, change the group of tcpdump and set permissions

chgrp pcap /usr/sbin/tcpdump
chmod 750 /usr/sbin/tcpdump
Finally, use setcap to give tcpdump the necessary permissions

setcap cap_net_raw,cap_net_admin=eip /usr/sbin/tcpdump
Be careful, that this will allow everybody from the group pcap to manipulate network interfaces and read raw packets!


http://askubuntu.com/questions/530920/tcpdump-permissions-problem

More details from

http://peternixon.net/news/2012/01/28/configure-tcpdump-work-non-root-user-opensuse-using-file-system-capabilities/

Issue:

DEV: eno16777736
pcap_open_live(): eno16777736: You don't have permission to capture on that device (socket: Operation not permitted)


----------------------------------ooOOOOoo---------------------------------------

wireshark:
sudo apt-get install wireshark

# Allowing non super users to capture the packets
sudo groupadd wireshark
sudo usermod -a -G wireshark $USER
sudo chgrp wireshark /usr/bin/dumpcap
sudo chmod 750 /usr/bin/dumpcap
sudo setcap cap_net_raw,cap_net_admin=eip /usr/bin/dumpcap
sudo getcap /usr/bin/dumpcap

# Wireshark display filter
ip.addr == 10.0.0.1 && ip.ttl == 111

# using tshark with capture filter and printing summary to console and capturing full
# packets to the file.
sudo tshark -f "host 216.58.219.206" -i enp0s8 -w /tmp/ars.pcap -P

# starting wireshark with a pcap file for analysis
 sudo wireshark /tmp/ars.pcap "ip.addr == 216.58.219.206"


https://ask.wireshark.org/questions/16343/install-wireshark-on-ubuntu
https://wiki.wireshark.org/CaptureFilters
https://www.wireshark.org/docs/wsug_html_chunked/AppToolstshark.html


----------------------------------ooOOOOoo---------------------------------------

git:

Once two factor authentication is enabled for password use the token when doing git operations using https.

https://help.github.com/articles/caching-your-github-password-in-git/


Unable to push after two factor authentication enabled.

http://stackoverflow.com/questions/17659206/git-push-results-in-authentication-failed

If you enabled two-factor authentication in your Github account you won't be able to push via HTTPS using your accounts password. Instead you need to generate a personal access token. This can be done in the application settings of your Github account. Using this token as your password should allow you to push to your remote repository via HTTPS. Use your username as usual.
https://help.github.com/articles/https-cloning-errors#provide-access-token-if-2fa-enabled

You may also need to update the origin for your repository if set to https:

git remote -v 
git remote remove origin 
// Did not work : git remote add origin git@github.com:user/repo.git  

you can also do git remote add origin https://username:access-token@github.com/username/repo.git to store your personal access token. 

// Did not work: https://help.github.com/articles/caching-your-github-password-in-git/

git remote set-url origin https://github.com/zkirkland/Random-Python-Tests.git
This one works. But after wards you need to add 
git push --set-upstream origin master

may have to do git pull origin master 

git checkout -b <branch>
git push -u origin <branch>

try git branch and git pull commands to see if they are fine and test with git remote -v

https://confluence.atlassian.com/bitbucketserver/permanently-authenticating-with-git-repositories-776639846.html

git branch -d agent_deploy
git push origin --delete agent_deploy

renaming a branch locally and remotely

git branch -m old_branch new_branch         # Rename branch locally    
git push origin :old_branch                 # Delete the old branch    
git push --set-upstream origin new_branch   # Push the new branch, set local branch to track the new remote

git config --global credential.helper 'cache --timeout 72000'
git config --global color.ui true

Check out a new repo
git clone git://location/proj.git

Actually see what’s going on
gitk --all

Interactive adding for commits
git add -i

Unstage changes
git reset HEAD

Return to last committed state
git reset --hard

Undo a merge
git reset --hard [ID]
git reset --hard HEAD~[number back]

Undo a commit with message
git reset --soft HEAD^

Modify a commit
git commit --amend

Add more files to existing commit
git add ...
git commit --amend -C HEAD

Branches have diverged – just get up stream
git reset --hard @{upstream}

Checkout specific version of a file
git checkout [ID] [FILE]

Updating submodules
git submodule init
git submodule sync
git submodule update

Go through every submodule and checkout the head
git submodule foreach git checkout master
git submodule foreach git pull origin master
Or automatically merge
git submodule update --merge

Show difference between two branches
git diff [BRANCH 1]..[BRANCH 2]

Difference between two commits
git diff [ID1] [ID2]

Merge a branch back into master
git checkout master
git merge [BRANCH]

Show all branches
git branch --all

Checkout and track remote branch
git checkout -t [BRANCH]

Change the Origin remote url to use ssh or https
git remote -v 
origin	https://github.domain.com/engineering/code.git (fetch)
origin	https://github.domain.com/engineering/code.git (push)
git remote set-url origin git@github.domain.com:engineering/code.git
git remote -v
origin	git@github.domain.com:engineering/code.git (fetch)
origin	git@github.domain.com:engineering/code.git (push)

Also for mounted directories, better to use ssh repo and use 
ssh-add in the host and to login to guest machine (where the host source is mounted) ssh guest -A

Removing tags
git ls-remote --tags origin | awk '/agent-.*/ {print ":" $2}'  | grep -v "\}" 
git ls-remote --tags origin | awk '/agent-.*/ {print ":" $2}'  | grep -v "\}" | xargs git push origin

Similarly for removing these pre-release tags from a local git repo:

$ git tag -l | awk '/^(.*[a-z])$/ {print $1}'  | xargs git tag -d

Forked branch upstream remote and no push

git remote add upstream git@github.company.com:organization/code.git
git fetch upstream
git checkout --track origin/master
git merge master upstream/master
git remote set-url --push upstream no_push


# Pushing selective commits to remote
git push <remotename> <commit SHA>:<remotebranchname>

# changing the permissions of the file
@fooMonster article worked for me

# git ls-tree HEAD
100644 blob 55c0287d4ef21f15b97eb1f107451b88b479bffe    script.sh
As you can see the file has 644 permission (ignoring the 100). We would like to change it to 755:

# git update-index --chmod=+x script.sh
commit the changes

# git commit -m "Changing file permissions"
[master 77b171e] Changing file permissions
0 files changed, 0 insertions(+), 0 deletions(-)
mode change 100644 => 100755 script.sh

# selective commit push
up vote
685
down vote
To push up through a given commit, you can write:

git push <remotename> <commit SHA>:<remotebranchname>
provided <remotebranchname> already exists on the remote. (If it doesn't, you can use git push <remotename> <commit SHA>:refs/heads/<remotebranchname> to autocreate it.)



http://blog.siyelo.com/how-to-bulk-delete-remote-git-tags/

https://help.github.com/articles/changing-a-remote-s-url/

https://stackoverflow.com/questions/3230074/how-can-i-push-a-specific-commit-to-a-remote-and-not-previous-commits

https://stackoverflow.com/questions/10516201/updating-file-permissions-only-in-git

https://stackoverflow.com/questions/3230074/how-can-i-push-a-specific-commit-to-a-remote-and-not-previous-commits

----------------------------------ooOOOOoo---------------------------------------
virtualbox:

Dyanmic size for the harddisk does not mean it will grow unlike vmware. So set the size next in the screen dialog to 20GB or else ubuntu updates will fail.

Guest additions need to be intalled prior to getting resized windows.

https://www.virtualbox.org/manual/ch04.html#idp46457703730512

Again, as with Linux hosts, we recommend using DKMS if it is available for the guest system. If it is not installed, use this command for Ubuntu/Debian systems:

sudo apt-get update
sudo apt-get upgrade
sudo apt-get install dkms

Insert the VBoxGuestAdditions.iso CD file into your Linux guest's virtual CD-ROM drive, exactly the same way as described for a Windows guest in Section 4.2.1.1, “Installation”.


Now, after click the menu 'Device' -> 'Install Guest Additions', then type the following command:

sudo mount /dev/sr0 /media/cdrom
and the ISO file is mounted on /media/cdrom

so, after this run:

cd /media/cdrom
sudo ./VBoxLinuxAdditions.run

http://askubuntu.com/questions/321589/unable-to-mount-the-cd-dvd-image-on-the-machine-sandbox

Change to the directory where your CD-ROM drive is mounted and execute as root:

sh ./VBoxLinuxAdditions.run

Shared Folders from Guest OS:
With Linux guests, auto-mounted shared folders are mounted into the /media directory, along with the prefix sf_. For example, the shared folder myfiles would be mounted to /media/sf_myfiles on Linux and /mnt/sf_myfiles on Solaris.

The guest property /VirtualBox/GuestAdd/SharedFolders/MountPrefix determines the prefix that is used. Change that guest property to a value other than "sf" to change that prefix; see Section 4.7, “Guest properties” for details.

Note
Access to auto-mounted shared folders is only granted to the user group vboxsf, which is created by the VirtualBox Guest Additions installer. Hence guest users have to be member of that group to have read/write access or to have read-only access in case the folder is not mapped writable.
To change the mount directory to something other than /media, you can set the guest property /VirtualBox/GuestAdd/SharedFolders/MountDir.

usermod -a -G vboxsf $USER
reboot


sudo mount -t vboxsf share ~/host

Note that with this, the default mount options are used and all files are owned by root. This can be changed by adding some mount options. Options are passed on with the -o parameter. You can use multiple options with one parameter, seperate the values with a comma. See the man page of mount for more info on which options you can use. The User Manual also notes the options compatible with the Shared Folders. To mount the SF so that you are the owner of the files, use this command:
CODE: SELECT ALL   EXPAND VIEW
sudo mount -t vboxsf -o rw,uid=1000,gid=1000 share ~/host

If you want to have it mount automatically upon each boot, put the mount command in /etc/rc.local (Debian based distro's), or whatever script is run at the end of the boot process. The Shared Folders service should mount them automatically, but that doesn't always happen.
Using /etc/fstab has little effect, because that file is processed before the SF module is loaded and will fail to mount the share. Sometimes, the share does get mounted because the GA check for it when they are loaded upon boot, but it's very flaky, meaning it doesn't work most of the time. You're better of with the first option.
When you put the mount command in /etc/rc.local, so it's mounted at startup, you can't use the short notation for your home folder. During startup, everything is done through the root user, so using ~ for home, means it's the home folder of Root (/root). Change it to the full path. For example:
CODE: SELECT ALL   EXPAND VIEW
mount -t vboxsf share /home/<username>/host

https://forums.virtualbox.org/viewtopic.php?f=29&t=15868

----------------------------------ooOOOOoo---------------------------------------
Xterm:

http://scarygliders.net/2011/12/01/customize-xterm-the-original-and-best-terminal/

Introducing the .Xresources file.

and issue the following command.
xrdb -merge ~/.Xresources

Using this handy file, which you save in your home directory, you just plug in whatever you wish to customize your xterm sessions with.

Here’s my current .Xresources file contents…

xterm*faceName: DejaVu Sans Mono Book
xterm*faceSize: 11

! Every shell is a login shell by default (for inclusion of all necessary environment variables)
xterm*loginshell: true

! I like a LOT of scrollback...
xterm*savelines: 16384

! double-click to select whole URLs :D
xterm*charClass: 33:48,36-47:48,58-59:48,61:48,63-64:48,95:48,126:48

! DOS-box colours...
xterm*foreground: rgb:a8/a8/a8
xterm*background: rgb:00/00/00
xterm*color0: rgb:00/00/00
xterm*color1: rgb:a8/00/00
xterm*color2: rgb:00/a8/00
xterm*color3: rgb:a8/54/00
xterm*color4: rgb:00/00/a8
xterm*color5: rgb:a8/00/a8
xterm*color6: rgb:00/a8/a8
xterm*color7: rgb:a8/a8/a8
xterm*color8: rgb:54/54/54
xterm*color9: rgb:fc/54/54
xterm*color10: rgb:54/fc/54
xterm*color11: rgb:fc/fc/54
xterm*color12: rgb:54/54/fc
xterm*color13: rgb:fc/54/fc
xterm*color14: rgb:54/fc/fc
xterm*color15: rgb:fc/fc/fc

! right hand side scrollbar...
xterm*rightScrollBar: true
xterm*ScrollBar: true

! stop output to terminal from jumping down to bottom of scroll again
xterm*scrollTtyOutput: false



----------------------------------ooOOOOoo---------------------------------------
OVS

Adding new port to a bridge

sudo modprobe dummy
ip link setup dummy0
ip link set up dummy0
sudo ip link set up dummy0
sudo ovs-vsctl add-port s2 dummy0
sudo ovs-ctl show

Adding Mirror with all ports to a tap interface
sudo ovs-vsctl -- --id=@s2e2 get Port s2-eth2 -- --id=@m create Mirror name=tap select-all=true output-port=@s2e1 -- set bridge s2 mirrors=@m

Adding Mirror with a tap port and ignore any other ports inthe mirror
sudo ovs-vsctl -- --id=@m create mirror name=tap -- add bridge s2 mirrors @m -- --id=@p1 get port s2-eth3 -- --id=@p2 get port s2-eth4 -- --id=@tap get port s2-eth1 -- set mirror tap 'select_src_port=[@p1, @p2]' 'select_dst_port=[@p1, @p2]' -- set mirror tap output-port=@tap 

sudo ovs-vsctl list bridge s2
sudo ovs-vsctl list mirror tap

to remove a mirror 
sudo ovs-vsctl -- --id=@m get mirror tap -- remove bridge s2 mirrors @m

to remove all mirrors from a bridge
sudo ovs-vsctl clear bridge s2 mirrors

To check ovs status
service openvswitch-switch status
sudo ovs-vsctl show
sudo ovs-vsctl del-br

To stop ovs from starting on bootup

service openvswitch-switch stop

To start
service openvswitch-switch start





----------------------------------ooOOOOoo---------------------------------------

Mininet:

Create a topology by including the needed topology from the base topology as python class into the python script and choosing the same at startup.

tap topology file:

class mLinearTopo( Topo ):
    "Linear topology of k switches, with n hosts per switch."

    def build( self, k=2, n=1, **_opts):
        """k: number of switches
           n: number of hosts per switch"""
        self.k = k
        self.n = n

        if n == 1:
            genHostName = lambda i, j: 'h%s' % i
        else:
            genHostName = lambda i, j: 'h%ss%d' % ( j, i )

        lastSwitch = None
        for i in irange( 1, k ):
            # Add switch
            switch = self.addSwitch( 's%s' % i )
            # Add hosts to switch
            for j in irange( 1, n ):
                host = self.addHost( genHostName( i, j ) )
                self.addLink( host, switch )
                if i == 2:
                        print("Adding Second link for Switch 2 only")
                        self.addLink( host, switch )
            # Connect switch to previous
            if lastSwitch:
                self.addLink( switch, lastSwitch )
            lastSwitch = switch


Changes in the mn copy to run mininet:
from topo import mLinearTopo
TOPOS = { 'minimal': MinimalTopo,
          'linear': LinearTopo,
          'reversed': SingleSwitchReversedTopo,
          'single': SingleSwitchTopo,
          'tree': TreeTopo,
          'torus': TorusTopo,
          'mlinear' : mLinearTopo }


mininet> xterm h1
mininet> xterm h2
mininet> xterm h3
mininet> h3 python -m SimpleHTTPServer 80 &
mininet> h1 curl -I 10.0.0.3
mininet> h1 ping h3

----------------------------------ooOOOOoo---------------------------------------

curl programmatic compile dependencies.

sudo apt-get install libcurl4-openssl-dev

http://stackoverflow.com/questions/11471690/curl-h-no-such-file-or-directory


curl, repeated commands for bash

curl -I "10.0.0.3"

for (( ; ; )) ; do curl -I "10.0.0.3" ; done

for((i=0;i<100;i++)) do curl --connect-timeout 3 'http://www.google.com'; done;

for i in `seq 1 20`; do curl http://url; done

for i in $(seq 1 20); do curl "http://url"; done

ab -n 500 -c 20 http://www.example.com/

while :; do clear; your_command; sleep 2; done

To post usnig curl a JSON request 

curl -H "Content-Type: application/json" -X POST -d '[{ "key1:"val1", "key2":"val2", "key3":"val3", "key4":"val4", "key5":"val5", "key6":"val6" }]' http://127.0.0.1:8443/<name of the method that handles the request>

or put them in a file and pass it using 

curl -H "Content-Type: application/json" -X POST --data-binary @/tmp/rjson.txt http://127.0.0.1:8443/<name of the method that handles the request>

where the file is of the type 

[{ "key1:"val1", "key2":"val2", "key3":"val3", "key4":"val4", "key5":"val5", "key6":"val6" }]

to add a rule using CLI entirely so that we can manipulate the previous rule, use the following format 

echo '[{ "key1:"val1", "key2":"val2", "key3":"val3", "key4":"val4", "key5":"val5", "key6":"val6" }]' | url -H "Content-Type: application/json" -X POST -d @- http://127.0.0.1:8443/<name of the method that handles the request>

Simple curl command as above with tee can write to a file the output which can be listed out as part of the script and removed after use.

echo '[{ "key1:"val1", "key2":"val2", "key3":"val3", "key4":"val4", "key5":"val5", "key6":"val6" }]' | tee /tmp/scratch_pad.txt | curl -H "Content-Type: application/json" -X POST -d @- http://127.0.0.1:8443/<name of the method that handles the request>; echo ""; cat /tmp/scratch_pad.txt; rm /tmp/scratch_pad.txt

Simple curl command as above with tee can write to a file the output which can be listed out as part of the script and removed after use.
----------------------------------ooOOOOoo---------------------------------------

Simple webserver options 

while :; do nc -l 80 < simple_page.html ; done

simple HTML file

<!DOCTYPE html>
<html>
<body>

<h1>My First Heading</h1>

<p>My first paragraph.</p>

</body>
</html>

----------------------------------ooOOOOoo---------------------------------------

kernel source for ubuntu

Kernel Doxygen
http://kerneldox.com/


# First one installs headers for the image kernel
sudo apt-get source linux-image-$(uname -r)
# This installs the source for the image kernel
sudo apt-get install linux-source

# This may be needed 
sudo apt-get install libssl-dev


# After this if needed to allow kernel to be modified, do the following 
# per netmap instructions
*** kernel not configured.
*** 
*** The kernel directory must be ready for external module compilation.
*** You may need to issue the following or equivalent commands:
*** 
***     cd /usr/src/linux-headers-4.4.0-21
***     make oldconfig
***     make modules_prepare
***
***
***     Current configuration values:
***
*** kernel directory            /usr/src/linux-headers-4.4.0-21
*** linux version               - 
*** module file                 netmap.ko
*** subsystems                  generic monitor pipe vale
*** kernel sources              /usr/src/linux-source-4.4.0
*** requested drivers           i40e ixgbe igb e1000e e1000 veth.c forcedeth.c virtio_net.c r8169.c




https://wiki.ubuntu.com/Kernel/SourceCode

To enable dev_dbg messages in a specific kernel file:

#define DEBUG
before including <linux/device.h>

printk("%s: The calling process is \"%s\" (pid %i)\n",
        __FUNCTION__, current->comm, current->pid);

Writing Linux Device Drivers

The invaluable and comprehensive O’Reilly’s Linux Device Drivers book. The 3rd edition is for the 2.6 kernel and can be downloaded from http://lwn.net/Kernel/LDD3/
http://vger.kernel.org/~davem/skb_data.html – understanding skb’s for network drivers.
http://kerneltrap.org/
http://www.cs.utah.edu/dept/old/texinfo/glibc-manual-0.02/library_toc.html – the massive but descriptive GNU C library
http://www.faqs.org/docs/kernel/index.html – Linux kernel module programming guide
http://people.nl.linux.org/ftp/pub/anoncvs/kernelnewbies/documents/kdoc/kernel-api/linuxkernelapi.html – The Linux kernel API


----------------------------------ooOOOOoo---------------------------------------
disk cleanup ubuntu

sudo apt-get clean
sudo apt-get autoclean
sudo apt-get autoremove
sudo apt-get remove --purge linux-image-X.X.XX-XX-generic
sudo apt-get remove --purge linux-image-X.X.XX-XX-generic
dpkg --get-selections | grep linux-image

du -sk * | sort -nr | head -10

ls -lh /boot

show top 10 biggest subdirs in the current dir.
du -sk * | sort -nr | head -10

du –sh /var/cache/apt/archives

# Run this and kill the process holding the files which are large.
sudo lsof | grep '(deleted)'


http://www.howtogeek.com/howto/28502/how-to-free-up-a-lot-of-disk-space-on-ubuntu-linux-by-deleting-cached-package-files/

use filelight or kDirStat to see where the disk space is going visually
check if you have old kernels for deletion
ls -lh /boot

cleaning packages
sudo apt-get autoremove

sudo apt-get autoclean

see list of all installed packages, sorted by size. If you see something big and don't use it - uninstall it

dpkg-query -W --showformat='${Installed-Size} ${Package}\n' | sort -nr | less

clean unused language files with translations (there are tons of them)
sudo apt-get install localepurge

check content of /var/tmp/
du -sh /var/tmp/

check also
man deborphan

Search for big files:
find / -type f -size +1024k

or

find / -size +50000  -exec ls -lahg {} \;


uname -r
to check your current version, then

dpkg -l linux-image-* linux-headers-*
to see all the old kernels and header files, then

sudo apt-get remove linux-image-<XYZ> linux-headers-<XYZ>
the apt-get remove command supports wildcards, so you can do apt-get remove linux-image 3.0.* linux-headers-3.0.* for example, to get rid of many at once.


Remove all old kernel versions automatically
Attention: If you've just upgraded the kernel, reboot before deleting the older versions!
Remember to check which kernel you are using type:

uname -r
Then as root:

sudo apt-get remove --purge $(dpkg -l 'linux-*' | sed '/^ii/!d;/'"$(uname -r | sed "s/\(.*\)-\([^0-9]\+\)/\1/")"'/d;s/^[^ ]* [^ ]* \([^ ]*\).*/\1/;/[0-9]/!d')
read that thread to be safe not to remove needed kernels with this command!


sudo du -h /var/log
Or as rubo77 points out in commends, you could use the NCurses disk usage tool:

sudo ncdu /var/log


http://askubuntu.com/questions/5980/how-do-i-free-up-disk-space

----------------------------------ooOOOOoo---------------------------------------
Identifying the NIC card in ubuntu

lspci | awk '/net/ {print $1}' | xargs -i% lspci -ks %
00:03.0 Ethernet controller: Intel Corporation 82540EM Gigabit Ethernet Controller (rev 02)
	Subsystem: Intel Corporation PRO/1000 MT Desktop Adapter
	Kernel driver in use: e1000
	Kernel modules: e1000
.....

05:00.0 Ethernet controller: Intel Corporation I210 Gigabit Network Connection (rev 03)
	Subsystem: Super Micro Computer Inc Device 1533
	Kernel driver in use: igb

lspci | grep -i net

sudo ls /sys/class/net

----------------------------------ooOOOOoo---------------------------------------
virtualenv error on virtualbox 

virtualenv --always-copy testenv

https://github.com/pypa/virtualenv/issues/209

later ffi.h error for pip install

sudo apt-get update
sudo apt-get install libffi-dev g++ libssl-dev

https://github.com/bigchaindb/bigchaindb/issues/24

----------------------------------ooOOOOoo---------------------------------------
Getting X window applications from remote headless server without Desktop installed on the server

ssh -XC user@192.168.10.140

http://askubuntu.com/questions/163155/how-do-i-access-my-remote-ubuntu-server-via-x-windows-from-my-mac

----------------------------------ooOOOOoo---------------------------------------
Link up/down

ifconfig eth0 up
ifconfig eth0 down
----------------------------------ooOOOOoo---------------------------------------
adding users

sudo useradd -d /home/<username> -m <username>

sudo passwd <username>

sudo chsh -s /bin/bash <username>

sudo adduser <username> sudo

sudo usermod -a -G sudo <username>

cat /etc/passwd | grep <username>

Add NOPASSWD:ALL in visudo 

http://www.howtogeek.com/howto/ubuntu/add-a-user-on-ubuntu-server/

https://help.ubuntu.com/lts/serverguide/user-management.html

http://askubuntu.com/questions/325807/arrow-keys-tab-complete-not-working

http://askubuntu.com/questions/7477/how-can-i-add-a-new-user-as-sudoer-using-the-command-line

----------------------------------ooOOOOoo---------------------------------------
Setting prompt to include user name and path 

export PS1='$(whoami)@$(hostname):$(pwd)$ '
export PS1='$(whoami)@${HOSTNAME%%.*} [$(pwd)]# '



http://superuser.com/questions/601181/how-to-display-current-path-in-command-prompt-in-linuxs-sh-not-bash


----------------------------------ooOOOOoo---------------------------------------

Search only c and h files including cpp

alias grepch="grep --include=*.[ch] --include=*.cpp -nr"
alias grepc="grep --include=*.[c] --include=*.cpp -nr"
alias greph="grep --include=*.[h] -nr"

https://austinmarton.wordpress.com/
----------------------------------ooOOOOoo---------------------------------------

Perform some operation in a loop from bash shell

Perform some operation for every line in the output of a command, e.g. add .txt to every file in a directory:

ls /var/* | while read fname; do cp $fname $fname.txt; done

Instead of:

for fname in `ls /var/*`; do cp $fname $fname.txt; done

http://tldp.org/LDP/abs/html/string-manipulation.html

----------------------------------ooOOOOoo---------------------------------------

useful linux commands

Check all running services
ps xa

Find a particular process
ps xa | grep processName

Kill a process
kill -KILL processPID

Close the current process
ctrl + c

Sleep a process
ctrl + z

Put the process to the background (where n is job number)
bg %n

Bring the process to the foreground (where n is job number)
fg %n

Show the list of current jobs
jobs

Search command history
ctrl + r

View a file page by page
cat somefile | less

Search for a file containing some string
grep -lir "searchstring" ~/somedir/*

Display the current path
pwd

Show kernel modules currently loaded
lsmod

Find a file
locate file

Create a gzip archive
tar -czf output.tar.gz input files

Secure copy from local to remote
scp localfile username@servername:/home/username/

Find all files that end in ‘.c’, contain the text “what i want” but not the text “what i dont”:
find . -name "*.c" -exec grep -lR 'what/ i/ want' {} \; | xargs grep -L 'what/ i/ dont'

Check all running services
ps xa

Find a particular process
ps xa | grep processName

Kill a process
kill -KILL processPID

Close the current process
ctrl + c

Sleep a process
ctrl + z

Put the process to the background (where n is job number)
bg %n

Bring the process to the foreground (where n is job number)
fg %n

Show the list of current jobs
jobs

Search command history
ctrl + r

View a file page by page
cat somefile | less

Search for a file containing some string
grep -lir "searchstring" ~/somedir/*

Display the current path
pwd

Show kernel modules currently loaded
lsmod

Find a file
locate file

Remount the filesystem in read/write
mount -o remount,rw /

Determine file type, architecture, etc:
file somefile

Search for sometext in a number of PDF files:
ls *.pdf | xargs -I{} pdftotext {} - | grep "sometext"

Read a binary file in hex:
od -c filename | less

----------------------------------ooOOOOoo---------------------------------------

C pointer arithmetic and warnings.

Compliant Solution
Any valid pointer to void can be converted to intptr_t or uintptr_t and back with no change in value (see INT36-EX2). The C Standard guarantees that a pointer to void may be converted to or from a pointer to any object type and back again and that the result must compare equal to the original pointer. Consequently, converting directly from a char * pointer to a uintptr_t, as in this compliant solution, is allowed on implementations that support the uintptr_t type.

#include <stdint.h>
 
void f(void) {
  char *ptr;
  /* ... */
  uintptr_t number = (uintptr_t)ptr; 
  /* ... */
}

----------------------------------ooOOOOoo---------------------------------------

C packing and alignment 

typedef struct
{
     char Data1;
     int Data2;
     unsigned short Data3;
     char Data4;

}__attribute__((packed, aligned(1))) sSampleStruct;  


http://stackoverflow.com/questions/11770451/what-is-the-meaning-of-attribute-packed-aligned4?rq=1

why you should not 

http://digitalvampire.org/blog/index.php/2006/07/31/why-you-shouldnt-use-__attribute__packed/

http://www.catb.org/esr/structure-packing/


----------------------------------ooOOOOoo---------------------------------------
changing hostname 

Ubuntu change hostname command


sudo hostname <new_name> 

but if that name is not known in /etc/hosts need to add an entry for 127.0.0.1 along with localhost to map to <new_name>


The procedure to change the computer name on Ubuntu Linux:

Type the following command to edit /etc/hostname using nano or vi text editor:
sudo nano /etc/hostname

Delete the old name and setup new name.
Next Edit the /etc/hosts file:
sudo nano /etc/hosts
This file contains the hostname, if not chaning for some reason go ahead and modify this file.
sudo nano /etc/hostname

Replace any occurrence of the existing computer name with your new one.
Reboot the system to changes take effect:
sudo reboot

http://www.cyberciti.biz/faq/ubuntu-change-hostname-command/

----------------------------------ooOOOOoo---------------------------------------
pip and boto, openssl and cherrypy

sudo apt install python-pip
pip install --upgrade pip
sudo pip install boto
sudo pip install pyopenssl
sudo pip install pyOpenSSL
sudo apt-get update
sudo apt-get install libffi-dev g++ libssl-dev



Installing
CherryPy can be easily installed via common Python package managers such as setuptools or pip.

$ easy_install cherrypy
$ pip install cherrypy
You may also get the latest CherryPy version by grabbing the source code from Github:

$ git clone https://github.com/cherrypy/cherrypy
$ cd cherrypy
$ python setup.py install

http://docs.cherrypy.org/en/latest/install.html

----------------------------------ooOOOOoo---------------------------------------

renewing dhcp ip address 

sudo dhclient -r

# For restarting networking in case of issues
sudo /etc/init.d/networking restart

http://www.howtogeek.com/168168/renew-dhcp-address-in-linux/
----------------------------------ooOOOOoo---------------------------------------

simple loops in bash

for i in `seq 1 100000`; do  echo $i; curl -I "205.196.12.74"; done

http://tldp.org/HOWTO/Bash-Prog-Intro-HOWTO-7.html
 
----------------------------------ooOOOOoo---------------------------------------

Buring an ISO image on MAC osX

Convert the iso to dmg image

hdiutil convert -format UDRW -o /path/to/target.img /path/to/ubuntu.iso

diskutil list

find the disk by removing and repeating and inserting and repeating the command to ensure the right drive is selected.

if disk3 is selected you can proceed to burn the dmg as follows

sudo dd if=/path/to/ubuntu-14.04-desktop-i386.dmg of=/dev/rdiskN bs=1m

where rdiskN will be rdisk3 for disk3. r is required part of the name.

http://computers.tutsplus.com/tutorials/how-to-create-a-bootable-ubuntu-usb-drive-for-pc-on-a-mac--cms-21187

If facing an error resource busy....

try this and repeat the dd command 

sudo diskutil unmountDisk /dev/disk2

http://raspberrypi.stackexchange.com/questions/9217/resource-busy-error-when-using-dd-to-copy-disk-img-to-sd-card


----------------------------------ooOOOOoo---------------------------------------

mounting usb drives in ubuntu

Step 1. Check the blockobjects and the file systems that are assigned to those block objects.

lsblk


Here you see the blokdevice sdb with partition /sdb1. But it's not mounted. There's no file assigned to it.

Step 2. What kind of device is sdb?

sudo lshw 
or

sudo lshw | less


So the USB stick - the block device /sdb - has the logical name /dev/sdb. And the FAT32 filesystem on that stick has the logical name /dev/sdb1.

Step 3. Mounting the USB-stick

We will mount /dev/sdb1 to /media/usbstick

sudo mkdir /media/usbstick

sudo mount -t vfat /dev/sdb1 /media/usbstick 
Read the manpage of mount for other options.

Step 4. Did it work?

lsblk

Yes, we can see that the filesystem on the USB stick is mounted to /media/usbstick

Addendum : if there are no logical names like /dev/sdb, you should first create them. See this information about setting up and controling loop objects with the losetup command

http://askubuntu.com/questions/285539/detect-and-mount-objects


----------------------------------ooOOOOoo---------------------------------------
cronjab using commandline 

crontab -l | { cat; echo "0 0 0 0 0 some entry"; } | crontab -


command="php $INSTALL/indefero/scripts/gitcron.php"
job="0 0 * * 0 $command"
cat <(fgrep -i -v "$command" <(crontab -l)) <(echo "$job") | crontab -


http://stackoverflow.com/questions/878600/how-to-create-cronjob-using-bash

----------------------------------ooOOOOoo---------------------------------------
json parsing on command line like sed/awk

https://stedolan.github.io/jq/


----------------------------------ooOOOOoo---------------------------------------
cron.hourly scripts 

A script ending with .sh is not executed in /etc/cron.hourly folder:

https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=308911
Links or binaries inside a directory handled by run-parts (like /etc/cron.daily) will not run if a period is part of their name.
rename the script

mv /etc/cron.hourly/Hour-sound.sh /etc/cron.hourly/Hour-sound
or put the script-call into

/etc/crontab
which allows the .sh ending

http://askubuntu.com/questions/611336/why-putting-a-script-in-etc-cron-hourly-is-not-working

Running the scripts manually on-demand


16
down vote
favorite
2
I have been digging through my Linux system. To try and understand how it all works

In the /etc/crontab file. I see the following

# run-parts
01 * * * * root run-parts /etc/cron.hourly
02 4 * * * root run-parts /etc/cron.daily
22 4 * * 0 root run-parts /etc/cron.weekly
42 4 1 * * root run-parts /etc/cron.monthly


http://superuser.com/questions/402781/what-is-run-parts-in-etc-crontab-and-how-do-i-use-it

----------------------------------ooOOOOoo---------------------------------------
date conversions

for getting date in scripts 

$(date -u)

converting epoch to printable date 
use the following example for the epoch value 1473353891

administrator@:/tmp$ date --date '@1473353891'
Thu Sep  8 16:58:11 UTC 2016

date +'%Y-%m-%d'

2017-09-17
http://stackoverflow.com/questions/1401482/yyyy-mm-dd-format-date-in-shell-script

----------------------------------ooOOOOoo---------------------------------------

logrotate

administrator@hello-feature:/tmp$ sudo logrotate -df /etc/logrotate.d/feature_updater 
reading config file /etc/logrotate.d/feature_updater

Handling 1 logs

rotating pattern: /var/log/hello.log  forced from command line (12 rotations)
empty log files are not rotated, log files >= 104857600 are rotated earlier, old logs are removed
switching euid to 0 and egid to 4
considering log /var/log/hello.log
  log needs rotating
rotating log /var/log/hello.log, log->rotateCount is 12
Converted ' "-%Y%m%d-%s"' -> '"-%Y%m%d-%s"'
dateext suffix '"-20160908-1473353891"'
glob pattern '"-[0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9]-[0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9]"'
glob finding logs to compress failed
glob finding old rotated logs failed
renaming /var/log/hello.log to /var/log/hello.log"-20160908-1473353891"
creating new /var/log/hello.log mode = 0644 uid = 0 gid = 0
switching euid to 0 and egid to 0
administrator@hello-feature:/tmp$ more !$
more /etc/logrotate.d/feature_updater
/var/log/hello.log {
    su root adm
    maxsize 100M
    monthly
    rotate 12
        dateext
        dateformat "-%Y%m%d-%s"
    compress
    delaycompress
    missingok
    notifempty
    create 644 root root
}

more /etc/logrotate.d/logrotate_hello
/var/log/*hello*.log {
    su root adm
    maxsize 100M
    daily
    rotate 1
    dateext
    dateformat -%Y-%m-%d
    dateyesterday
    copytruncate
    compress
    delaycompress
    missingok
    notifempty
    create 644 root root
    postrotate
        /opt/hello/tools/support_files_export.sh > /dev/null
    endscript
    sharedscripts
}

/var/log/apache2/*_log {
        weekly
        missingok
        rotate 52
        compress
        delaycompress
        notifempty
        create 640 root adm
        sharedscripts
        postrotate
                if [ -f /var/run/apache2.pid ]; then
                        /etc/init.d/apache2 restart > /dev/null
                fi
        endscript
}

to force run 
logrotate -vf /etc/logrotate.d/apache2.conf


http://www.thecave.info/execute-logrotate-command-manually/



----------------------------------ooOOOOoo---------------------------------------

Virtualenv and Virtualbox shared folders issue

Shared folders on Virtualbox dont allow symbolic links for security reasons.

So virtualenv creation fails with Read only error for filesystem.

Two options

use copy mode for virtualenv

virtualenv --always-copy venv


OR 

change VirtualBox settings using 

My steps to fix it:
1. Use virtualenv==1.8.2 (not working with 1.8.4!)
2. setextradata in host OS:

VBoxManage setextradata CENTOS VBoxInternal2/SharedFoldersEnableSymlinksCreate/home/oe 1
, where CENTOS - Virtualbox OS name, /home/oe - name of mounted folder
3. Mount device in guest OS with read-write permissions:

sudo mount -t vboxsf -o rw,uid=1000 shared_folder /mnt/shared_folder
, where uid=1000 - uid of current user in guest OS (see /etc/passwd).

https://github.com/pypa/virtualenv/issues/209

----------------------------------ooOOOOoo---------------------------------------

Deplaying OVA to ESXi using ovftool

$ ovftool --disableVerification  --noSSLVerify --datastore=datastore1 --network="VM Network" ~/images/PA-VM-ESX-7.1.0.ova  vi://root@192.168.10.138

http://www.vmwarebits.com/content/import-and-export-virtual-machines-command-line-vmwares-ovf-tool


----------------------------------ooOOOOoo---------------------------------------
git stash 

git stash apply stash@{n}

git stash list

git stash clear

git stash pop

git stash save "Message"

http://stackoverflow.com/questions/1910082/git-stash-apply-version


for regular patch 

git apply <diff>

git apply --stat 

git apply --check

https://git-scm.com/docs/git-apply

----------------------------------ooOOOOoo---------------------------------------

pgrep amd pkill examples with regex

pgrep and pkill
-u is for process belonging to that user
-f will match the whole command line and not just process name which is by default

  pgrep -u feature autossh
  pgrep -u feature ssh
  ps -eaf | grep "10.10.16.5:10443" | grep -v grep | awk 'print $(2)' 
  ps -eaf | grep "10.10.16.5:10443" | grep -v grep | awk 'print $(2)' | xargs kill
  pgrep -f  "^.*ssh.*10022.*$"
  pkill -f  "^.*ssh.*10022.*$"

----------------------------------ooOOOOoo---------------------------------------
network configuration static IP in ubuntu

Set your IP address changes in /etc/network/interfaces. Example:

auto eth0
iface eth0 inet static

address 192.168.1.128
netmask 255.255.255.0
network 192.168.1.0
broadcast 192.168.1.255
gateway 192.168.1.1
Don't give your DNS configurations in /etc/resolv.conf because while we restart the server sometimes the configuration get erased.

So use vim /etc/resolvconf/resolv.conf.d/base (while updating configs in this it doesn't get removed)

example:

search  (domain name)
nameserver 8.8.8.8
nameserver 8.8.4.4
Save and then restart your server, this fixed my static issue! :)

http://askubuntu.com/questions/470237/assigning-a-static-ip-to-ubuntu-server-14-04-lts

----------------------------------ooOOOOoo---------------------------------------

Using Host DNS from the Guest VMs in VirtualBox

VBoxManage list vms
VBoxManage list runningvms

VBoxManage modifyvm "VM name" --natdnshostresolver1 on

http://superuser.com/questions/641933/how-to-get-virtualbox-vms-to-use-hosts-dns

----------------------------------ooOOOOoo---------------------------------------

Using default interface names for eth0, eth1 in ubuntu

ubuntu-16.04-server-amd64

In the grub file, change

GRUB_CMDLINE_LINUX=""
to

GRUB_CMDLINE_LINUX="net.ifnames=0"
Then, type in:

sudo update-grub
and reboot your system

sudo reboot

http://askubuntu.com/questions/767786/changing-network-interfaces-name-ubuntu-16-04

----------------------------------ooOOOOoo---------------------------------------

Installing JDCK and maven

sudo apt-get install maven

You got wrong package installed. The one which you instlled is not for Debian/ubuntu, its for Fedora, Oracle Linux, Red Hat Enterprise Linux, etc. Refer this link on OpenJDK site. Do

sudo apt-get install openjdk-8-jdk
Before running above, I would suggest you delete the wrong package using

sudo apt-get purge java-1.8.0-openjdk-devel

http://askubuntu.com/questions/683797/javac-package-is-missing

JDK 8

Debian, Ubuntu, etc.

On the command line, type:

$ sudo apt-get install openjdk-8-jre
The openjdk-8-jre package contains just the Java Runtime Environment. If you want to develop Java programs then please install the openjdk-8-jdk package.

Fedora, Oracle Linux, Red Hat Enterprise Linux, etc.

On the command line, type:

$ su -c "yum install java-1.8.0-openjdk"
The java-1.8.0-openjdk package contains just the Java Runtime Environment. If you want to develop Java programs then install the java-1.8.0-openjdk-devel package.

http://openjdk.java.net/install/


user@lubuntu-vm:~$ ls -l /usr/bin/java
lrwxrwxrwx 1 root root 22 Sep  8 15:12 /usr/bin/java -> /etc/alternatives/java

user@lubuntu-vm:~$ ls -l /etc/alternatives/java
lrwxrwxrwx 1 root root 46 Sep  8 15:12 /etc/alternatives/java -> /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java
user@lubuntu-vm:~$ ls -l /usr/lib/jvm/
total 4
lrwxrwxrwx 1 root root   24 Feb 25  2016 default-java -> java-1.8.0-openjdk-amd64
lrwxrwxrwx 1 root root   20 Jul 20 22:49 java-1.8.0-openjdk-amd64 -> java-8-openjdk-amd64
drwxr-xr-x 5 root root 4096 Sep  8 15:12 java-8-openjdk-amd64


user@lubuntu-vm:~$ update-alternatives --config java
There is only one alternative in link group java (providing /usr/bin/java): /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java
Nothing to configure.

user@lubuntu-vm:~$ JAVA_HOME=/usr/lib/jvm/default-java
user@lubuntu-vm:~$ export JAVA_HOME

user@lubuntu-vm:~$ mvn --version
Apache Maven 3.3.9
Maven home: /usr/share/maven
Java version: 1.8.0_91, type: Oracle Corporation
Java home: /usr/lib/jvm/java-8-openjdk-amd64/jre
Default locale: en_US, platform encoding: UTF-8
OS name: "linux", version: "4.4.0-36-generic", arch: "amd64", family: "unix"
user@lubuntu-vm:~$ 

----------------------------------ooOOOOoo---------------------------------------

git getting repository root

anand.parthasarathy@mock-local:/media/sf_hDocuments/code/feature-agent$ git rev-parse --show-cdup

anand.parthasarathy@mock-local:/media/sf_hDocuments/code/feature-agent$ pwd
/media/sf_hDocuments/code/feature-agent
anand.parthasarathy@mock-local:/media/sf_hDocuments/code/feature-agent$ cd iso
anand.parthasarathy@mock-local:/media/sf_hDocuments/code/feature-agent/iso$ git rev-parse --show-cdup
../
anand.parthasarathy@mock-local:/media/sf_hDocuments/code/feature-agent/iso$ git rev-parse --show-top-level
--show-top-level
anand.parthasarathy@mock-local:/media/sf_hDocuments/code/feature-agent/iso$ git rev-parse --show-toplevel
/media/sf_hDocuments/code/feature-agent

http://stackoverflow.com/questions/957928/is-there-a-way-to-get-the-git-root-directory-in-one-command
----------------------------------ooOOOOoo---------------------------------------

rsyslog

i$umask 0000

$FileCreateMode 0666

# A template that resambles traditional syslogd file output:
$template TraditionalFormat,"%timegenerated% %HOSTNAME% %syslogtag%%msg:::drop-last-lf%\n"

# A more verbose template:
$template precise,"%syslogpriority%,%syslogfacility%,%timegenerated::fulltime%,%HOSTNAME%,%syslogtag%,%msg%\n"

# A template that resembles RFC 3164 on-the-wire format:
# (yes, there is NO space betwen syslogtag and msg! that's important!)
$template RFC3164fmt,"<%PRI%>%TIMESTAMP% %HOSTNAME% %syslogtag%%msg%"

# a template resembling traditional wallmessage format:
$template wallmsg,"\r\n\7Message from syslogd@%HOSTNAME% at %timegenerated% ...\r\n %syslogtag%%msg%\n\r"

# The template below emulates winsyslog format, but we need to check the time
# stamps used. It is also a good sampleof the property replacer in action.
$template WinSyslogFmt,"%HOSTNAME%,%timegenerated:1:10:date-rfc3339%,%timegenerated:12:19:date-rfc3339%,%timegenerated:1:10:date-rfc3339%,%timegenerated:12:19:date-rfc3339%,%syslogfacil
ity%,%syslogpriority%,%syslogtag%%msg%\n"

# A template used for database writing (notice it *is* an actual
# sql-statement):
$template dbFormat,"insert into SystemEvents (Message, Facility,FromHost, Priority, DeviceReportedTime, ReceivedAt, InfoUnitID, SysLogTag) values ('%msg%', %syslogfacility%, '%HOSTNAME%
',%syslogpriority%, '%timereported:::date-mysql%', '%timegenerated:::date-mysql%', %iut%, '%syslogtag%')",sql

#
# Area1 custom
$template comp,"%timegenerated% %syslogtag% LOG-%syslogpriority%-%syslogpriority-text:::uppercase%:%msg%\n"
$ActionFileDefaultTemplate comp

:rawmsg,contains,"comp_feature" /var/log/comp.log

& ~


Add to a file number that can be picked up before 50-default.conf is read. This way your directives will be taken over other directives.:w

http://www.rsyslog.com/doc/v8-stable/configuration/templates.html

http://www.rsyslog.com/how-to-bind-a-template/


----------------------------------ooOOOOoo---------------------------------------

shell functions

#
# Exit, run and critical command execution wrapper functions
#
# Exit Trap functions 
exit_trap () {
  local lc="$BASH_COMMAND" rc=$?
  echo "Command [$lc] exited with code [$rc]" | tee -a ${FORTIFY_UPDATER_LOG_FILE} > /dev/null
}

# Exit option if we are handling the command status.
die() { echo >&2 -e "\nERROR: $@\n" | tee -a ${FORTIFY_UPDATER_LOG_FILE} > /dev/null exit 1; }

# run a command but dont fail the script if it fails, just log 
run() { set +e; "$@"; code=$?; [ $code -ne 0 ] && echo "command [$*] failed with error code $code"; set -e; }

# run the command and exit if it fails with a log
run_critical() { "$@"; code=$?; [ $code -ne 0 ] && die "command [$*] failed with error code $code"; }


# Script exits on any command failure. Better to set the trap to log if we die
trap exit_trap EXIT
set -e

# Treat unset variables as failure
set -u
# Pipe command status is first failed command status
set -o pipefail


#
# Utility functions 
#
copy_file ()
{
    if [ -f $1 ]; then
        echo "copying $1 to $2" | tee -a ${DEF_LOG_FILE} > /dev/null
        cp $1 $2
    else
        echo "$FUNCNAME (): cannot find $1"  | tee -a ${DEF_LOG_FILE} > /dev/null
    fi
}

if [ $? -eq 0 ]; then
    echo OK
else
    echo FAIL
fi


can use run copy_file 
it still works as expected

----------------------------------ooOOOOoo---------------------------------------
ntp updates

sudo ntpdate -s time.nist.gov

sudo timedatectl set-timezone Etc/UTC

----------------------------------ooOOOOoo---------------------------------------

mounting the filessystem for read write in ubuntu recovery.

mount -o remount,rw / 
----------------------------------ooOOOOoo---------------------------------------

find options 

-mtime N means files whose age A in days satisfies N ≤ A < N+1. In other words, -mtime N selects files that were last modified between N and N+1 days ago.

-mtime -N means files whose age A satisfies A < N, i.e. files modified less than N days ago. Less intuitively, -mtime +N means files whose age A satisfies N+1 ≤ A, i.e. files modified at least N+1 days ago.

For example, -mtime 1 selects files that were modified between 1 and 2 days ago. -mtime +1 selects files that were modified at least 2 days ago. To get files modified at least 1 day ago, use -mtime +0.

The description “was last modified n*24 hours ago” is only an approximation, and not a veryclear one.

If you find these rules hard to remember, use a reference file instead.

touch -d '1 day ago' cutoff
find . -newer cutoff
(The syntax “1 day ago” requires GNU touch.)


Fractional 24-hour periods are truncated! That means that “find -mtime +1” says to match files modified two or more days ago.

find . -mtime +0 # find files modified greater than 24 hours ago
find . -mtime 0 # find files modified between now and 1 day ago
# (i.e., in the past 24 hours only)
find . -mtime -1 # find files modified less than 1 day ago (SAME AS -mtime 0)
find . -mtime 1 # find files modified between 24 and 48 hours ago
find . -mtime +1 # find files modified more than 48 hours ago
The following may only work on GNU?

find . -mmin +5 -mmin -10 # find files modified between
# 6 and 9 minutes ago
find / -mmin -10 # modified less than 10 minutes ago



http://unix.stackexchange.com/questions/92346/why-does-find-mtime-1-only-return-files-older-than-2-days

----------------------------------ooOOOOoo---------------------------------------

date for yesterday and day before or any other day

For yesterday,

date -d '-1 day' '+%Y%d%m'
For day before yesterday,

date -d '-2 day' '+%Y%d%m'

http://stackoverflow.com/questions/22043088/how-to-get-yesterday-and-day-before-yesterday-in-linux
----------------------------------ooOOOOoo---------------------------------------

rename

rename -vnf 's/agent_log/DNR-agent_log/' agent_log*2016-10-22*.log

https://www.maketecheasier.com/rename-files-in-linux/

----------------------------------ooOOOOoo---------------------------------------

date conversions

anand.parthasarathy@feature-local:/data/log/feature_agent_logs/$ date -d "Fri Oct 28 02:00:53 PDT 2016" +%s
1477645253
anand.parthasarathy@feature-local:/data/log/feature_agent_logs/$ date -d "Fri Oct 28 02:00:53 PDT 2016" -u +%s
1477645253
anand.parthasarathy@feature-local:/data/log/feature_agent_logs/$ date -u --date @1477645253
Fri Oct 28 09:00:53 UTC 2016
anand.parthasarathy@feature-local:/data/log/feature_agent_logs/$ date +%s
1477671390
anand.parthasarathy@feature-local:/data/log/feature_agent_logs/$ 

comp@host:~/comp/feature-agent$ cat iso/feature/build_time
Fri Oct 28 22:56:58 UTC 2016
comp@host:~/comp/feature-agent$ date -d "$(cat iso/feature/build_time)" +%s
1477695418
comp@host:~/comp/feature-agent$ date -u --date @1477695418
Fri Oct 28 22:56:58 UTC 2016
comp@host:~/comp/feature-agent$ date -u --date @1477695418 +%Y-%m-%d_%H:%M:%S
2016-10-28_22:56:58

$ date -d "$(cat build_time)" +%Y-%m-%d_%H:%M:%S
2016-10-28_17:17:16
$ cat build_time
Sat Oct 29 00:17:16 UTC 2016
$ date -u -d "$(cat build_time)" +%Y-%m-%d_%H:%M:%S
2016-10-29_00:17:16
$ date -u -d "$(cat build_time)" +%Y-%m-%d_%H-%M-%S
2016-10-29_00-17-16



http://stackoverflow.com/questions/1092631/get-current-time-in-seconds-since-the-epoch-on-linux-bash

----------------------------------ooOOOOoo---------------------------------------

git config when not natively authenticated and not having global config set.
----------------------------------ooOOOOoo---------------------------------------

cut command 

$ ls update.tar.gz* | cut -d - -f 1 
update.tar.gz
$ echo $(ls update.tar.gz* | cut -d - -f 1 )
update.tar.gz

----------------------------------ooOOOOoo---------------------------------------

cscope 

export CSCOPE_EDITOR=`which emacs`

find . -name "*.c" -o -name "*.cpp" -o -name "*.h" -o -name "*.hpp" > cscope.files
find . -name "*.java" -o -name "*.xml" > cscope.files

cscope -q -R -b -i cscope.files

cscope -d

https://courses.cs.washington.edu/courses/cse451/12sp/tutorials/tutorial_cscope.html

----------------------------------ooOOOOoo---------------------------------------

decoding crashes without core

If this were a program, not a shared library
Run
 addr2line -e yourSegfaultingProgram 00cd6df4
edited Sep 3 '13 at 19:59
Peter
9,033 9 30
asked Sep 3 '13 at 8:20
skg
504 10 23
                      http://stackoverflow.com/questions/18587360/ubuntu-segfault-at-125-ip-00cd6df4-sp-bfeef720-error-6-in-libqtcore-so-4-7-4b5?noredirect=1&lq=1 2/3
11/16/2016 linux - Ubuntu: segfault at 125 ip 00cd6df4 sp bfeef720 error 6 in libQtCore.so.4.7.4[b51000+2ca000]? - Stack Overflow
(and repeat for the other instruction pointer values given) to see where the error is happening. Better, get a debug­instrumented build, and reproduce the problem under a debugger such as gdb.
Since it's a shared library
You're hosed, unfortunately; it's not possible to know where the libraries were placed in memory by the dynamic linker after­the­fact. Reproduce the problem under gdb.
What the error means
Here's the breakdown of the fields:
address ­ the location in memory the code is trying to access (it's likely that 10 and 11 are offsets from a pointer we expect to be set to a valid value but which is instead pointing to 0)
ip ­ instruction pointer, ie. where the code which is trying to do this lives
sp ­ stack pointer
error ­ value of errno, ie. last error code which was reported by a syscall
Also When system requests fail, error code are returned. To understand the nature of the error these codes need to be interpreted. They are recorded in:­
/usr/include/asm/errno.h

ex:

Nov 21 10:57:27 kernel: LOG-6-INFO:[2386015.680183] process_feature[7263]: segfault at 20 ip 0000000000403614 sp 00007fd054b57de0 error 4 in process_feature[400000+1a000]
user@host:~$ sudo addr2line -e /feature/bin/process_feature 0000000000403614
/home/user/feature/src/process_feature_main.c:74 (discriminator 1)


http://stackoverflow.com/questions/18587360/ubuntu-segfault-at-125-ip-00cd6df4-sp-bfeef720-error-6-in-libqtcore-so-4-7-4b5?noredirect=1&lq=1
----------------------------------ooOOOOoo---------------------------------------

vim rc files

" Only do this part when compiled with support for autocommands.
if has("autocmd")
    " Use filetype detection and file-based automatic indenting.
    filetype plugin indent on

    " Use actual tab chars in Makefiles.
    autocmd FileType make set tabstop=8 shiftwidth=8 softtabstop=0 noexpandtab
endif
" For everything else, use a tab width of 4 space chars.
set tabstop=4       " The width of a TAB is set to 4.
                    " Still it is a \t. It is just that
                    " Vim will interpret it to be having
                    " a width of 4.
set shiftwidth=4    " Indents will have a width of 4.
set softtabstop=4   " Sets the number of columns for a TAB.
set expandtab       " Expand TABs to spaces.
set smartindent
set cindent
set paste
syn on

----------------------------------ooOOOOoo---------------------------------------
UTC time
sudo dpkg-reconfigure tzdata
then go to "Etc" or "None of the above", there to UTC, enter, you're done. It actually changes files /etc/timezone and /etc/localtime.

http://askubuntu.com/questions/117359/how-do-i-change-the-timezone-to-utc
----------------------------------ooOOOOoo---------------------------------------

macosX changing creation time and modified time 

touch –mt 201006301525 /Volumes/Mac\ HD/Pictures/myfile.jpg

http://blog.grapii.com/2010/07/change-a-files-creationmodified-date-on-mac-os-x/
----------------------------------ooOOOOoo---------------------------------------
JQ JSON parser for bash

administrator@compo-feature:/usr/local/compo/service/etc$ jq '.objects[] | select(.type == "compo")' compo.json
{
  "key": "Really you need a key ?",
  "some_value": 360,
  "url": "http://service-local",
  "type": "compo",
  "object_timer": 400,
  "username": "Who am i ",
  "periodic_timer": 8640,
  "visibility_timer": 980,
  "cmp_cfg_attrib": "Compo-Type-1"
}
administrator@compo-feature:/usr/local/compo/service/etc$ jq '.objects[] | select(.type == "compo") | .url' compo.json
"http://service-local"
administrator@compo-feature:/usr/local/compo/service/etc$ jq '.objects[] | select(.type == "compo") | .key' compo.json
"Really you need a key ?"
administrator@compo-feature:/usr/local/compo/service/etc$ jq '.objects[] | select(.type == "compo") | .username' compo.json
"Who am i "
administrator@compo-feature:/usr/local/compo/service/etc$ sudo cp compo.json compo.json.test
administrator@compo-feature:/usr/local/compo/service/etc$ vi !$
vi compo.json.test
administrator@compo-feature:/usr/local/compo/service/etc$ sudo vi !$
sudo vi compo.json.test
administrator@compo-feature:/usr/local/compo/service/etc$ jq '.objects[] | select(.type == "compo") | .url' compo.json.test
"http://service-local"
administrator@compo-feature:/usr/local/compo/service/etc$ jq '.objects[] | select(.type == "compo") | .username' compo.json.test
"Who am i "
administrator@compo-feature:/usr/local/compo/service/etc$ jq '.objects[] | select(.type == "compo") | .key' compo.json.test
"Really you need a key ?"

administrator@compo-feature:/usr/local/compo/service/etc$ jq '.objects[] | select(.type == "compo") | .url' compo.json.test | head -1
"http://service-local"

# eliminate missing keys and also the null return values when the key is not present. 
administrator@compo-feature:/usr/local/compo/service/etc$ jq '.objects[] | select(.type == "compo")  | select (. | has("key")) | .key' compo.json.test | head -1
"http://service-local"

https://stedolan.github.io/jq/
https://stedolan.github.io/jq/manual/#Builtinoperatorsandfunctions

http://blog.librato.com/posts/jq-json
http://linuxcommando.blogspot.com/2008/03/using-sed-to-extract-lines-in-text-file.html


----------------------------------ooOOOOoo---------------------------------------
----------------------------------ooOOOOoo---------------------------------------
----------------------------------ooOOOOoo---------------------------------------
